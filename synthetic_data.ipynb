{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc80496-43de-45f7-9dfc-adc060da183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187fa769-fd30-4bc9-a786-74da757eb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of rows to generate (100,000 rows)\n",
    "num_rows = 100000\n",
    "\n",
    "# Generate synthetic data for DRASTIC parameters\n",
    "depth_to_water = np.random.uniform(5, 50, num_rows)  # Depth to water table in meters\n",
    "net_recharge = np.random.uniform(50, 300, num_rows)  # Net recharge in mm/year\n",
    "aquifer_media = np.random.choice([1, 2, 3, 4, 5], num_rows)  # Categorical values for aquifer media\n",
    "soil_media = np.random.choice([1, 2, 3, 4], num_rows)  # Categorical values for soil media\n",
    "topography = np.random.uniform(0, 10, num_rows)  # Slope percentage\n",
    "vadose_zone = np.random.choice([1, 2, 3, 4, 5], num_rows)  # Categorical values for vadose zone\n",
    "hydraulic_conductivity = np.random.uniform(0.01, 0.1, num_rows)  # Conductivity in m/s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec951273-e3b0-4cc4-a236-4ad44ff5342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the DRASTIC index with weighted parameters\n",
    "drastic_index = (depth_to_water * 5 +\n",
    "                 net_recharge * 4 +\n",
    "                 aquifer_media * 3 +\n",
    "                 soil_media * 2 +\n",
    "                 topography * 1 +\n",
    "                 vadose_zone * 5 +\n",
    "                 hydraulic_conductivity * 3)\n",
    "\n",
    "# Normalize the DRASTIC index between 0 and 1\n",
    "drastic_index = (drastic_index - drastic_index.min()) / (drastic_index.max() - drastic_index.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d75e563-394b-4983-88fd-d7b01896c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100,000 rows of synthetic data have been saved to 'synthetic_drastric_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with all the parameters and the DRASTIC index\n",
    "synthetic_data = pd.DataFrame({\n",
    "    'Depth_to_Water': depth_to_water,\n",
    "    'Net_Recharge': net_recharge,\n",
    "    'Aquifer_Media': aquifer_media,\n",
    "    'Soil_Media': soil_media,\n",
    "    'Topography': topography,\n",
    "    'Vadose_Zone': vadose_zone,\n",
    "    'Hydraulic_Conductivity': hydraulic_conductivity,\n",
    "    'DRASTIC_Index': drastic_index\n",
    "})\n",
    "\n",
    "# Save the synthetic data to a CSV file\n",
    "synthetic_data.to_csv('synthetic_drastric_data.csv', index=False)\n",
    "\n",
    "print(\"100,000 rows of synthetic data have been saved to 'synthetic_drastric_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd17f4ed-722e-4603-84ea-4d24e28e9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate synthetic contamination levels based on DRASTIC values\n",
    "# You can make contamination a function of DRASTIC index + some noise\n",
    "contamination_level = drastic_index * 100 + np.random.normal(0, 10, num_rows)  # Add some noise\n",
    "# Create a DataFrame with all the parameters, DRASTIC index, and contamination levels\n",
    "synthetic_data = pd.DataFrame({\n",
    "    'Depth_to_Water': depth_to_water,\n",
    "    'Net_Recharge': net_recharge,\n",
    "    'Aquifer_Media': aquifer_media,\n",
    "    'Soil_Media': soil_media,\n",
    "    'Topography': topography,\n",
    "    'Vadose_Zone': vadose_zone,\n",
    "    'Hydraulic_Conductivity': hydraulic_conductivity,\n",
    "    'DRASTIC_Index': drastic_index,\n",
    "    'Contamination_Level': contamination_level  # Target variable for regression\n",
    "})\n",
    "# Save the synthetic data to a CSV file (optional)\n",
    "synthetic_data.to_csv('synthetic_drastric_data_with_contamination.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f79a933-a434-429f-bd41-e68bcccd328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 106.17665991520298\n",
      "R-squared: 0.8424473404241759\n",
      "Actual vs Predicted contamination levels have been saved to 'actual_vs_predicted_contamination.csv'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the 'data' DataFrame with DRASTIC parameters and contamination levels\n",
    "\n",
    "# Step 1: Split data into features (X) and target (y)\n",
    "X = synthetic_data.drop(['DRASTIC_Index', 'Contamination_Level'], axis=1)  # Features: DRASTIC parameters\n",
    "y = synthetic_data['Contamination_Level']  # Target: Contamination level\n",
    "\n",
    "# Step 2: Split into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Initialize and train a Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Step 6: Create a DataFrame with Actual vs Predicted contamination levels\n",
    "comparison_df = pd.DataFrame({'Actual_Contamination': y_test, 'Predicted_Contamination': y_pred})\n",
    "\n",
    "# Step 7: Save the comparison to a CSV file\n",
    "comparison_df.to_csv('actual_vs_predicted_contamination.csv', index=False)\n",
    "\n",
    "print(\"Actual vs Predicted contamination levels have been saved to 'actual_vs_predicted_contamination.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bd08a2-1928-4bc0-abb3-8330279d382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Categorize contamination levels (low, medium, high)\n",
    "synthetic_data['Contamination_Category'] = pd.qcut(synthetic_data['Contamination_Level'], 3, labels=['low', 'medium', 'high'])\n",
    "\n",
    "# Step 3: Split the data into features (X) and target (y)\n",
    "X = synthetic_data.drop(['Contamination_Level', 'Contamination_Category'], axis=1)\n",
    "y = synthetic_data['Contamination_Category']  # Target is the contamination category (low, medium, high)\n",
    "\n",
    "# Step 4: Split into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "800b0bc2-8ac7-42e2-932a-0048feb36ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC(random_state=42)\n",
    "log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Dictionary to store results for each model\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79b02d-5080-413a-ac7c-9177435ba824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70cef5bf-5c47-4b1a-845e-2dd843ae22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to train and evaluate each model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate classification scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Calculate errors (treating categories as numeric for error calculations)\n",
    "    y_test_numeric = y_test.cat.codes  # Convert categories to numeric for error calculation\n",
    "    y_pred_numeric = pd.Categorical(y_pred, categories=y_test.cat.categories).codes\n",
    "    \n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    r2 = r2_score(y_test_numeric, y_pred_numeric)\n",
    "    \n",
    "    return accuracy, f1, precision, recall, rmse, r2\n",
    "\n",
    "# Evaluate Random Forest\n",
    "results['Random Forest'] = evaluate_model(rf_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "results['SVM'] = evaluate_model(svm_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "results['Logistic Regression'] = evaluate_model(log_reg_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28289658-c2f0-42e9-a5bc-25c63d4e95d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison:\n",
      "\n",
      "Random Forest:\n",
      "  Accuracy: 0.7967\n",
      "  F1 Score: 0.7965\n",
      "  Precision: 0.7963\n",
      "  Recall: 0.7967\n",
      "  RMSE: 10.3042\n",
      "  R-squared: 0.6933\n",
      "\n",
      "SVM:\n",
      "  Accuracy: 0.8008\n",
      "  F1 Score: 0.8000\n",
      "  Precision: 0.7994\n",
      "  Recall: 0.8008\n",
      "  RMSE: 10.3042\n",
      "  R-squared: 0.6998\n",
      "\n",
      "Logistic Regression:\n",
      "  Accuracy: 0.8007\n",
      "  F1 Score: 0.8003\n",
      "  Precision: 0.7999\n",
      "  Recall: 0.8007\n",
      "  RMSE: 10.3042\n",
      "  R-squared: 0.6998\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Print Results\n",
    "print(\"Model Comparison:\")\n",
    "for model_name, (accuracy, f1, precision, recall, rmse, r2) in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6075ad9f-ffe6-4b93-a362-3c011a4ab9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the DRASTIC parameters to predict vulnerability:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Depth to Water (e.g., 25):  6.878527377717779\n",
      "Net Recharge (e.g., 150):  168.02644995842303\n",
      "Aquifer Media (1-5, e.g., 3):  4\n",
      "Soil Media (1-4, e.g., 2):  3\n",
      "Topography (e.g., 5):  2.396136594242184\n",
      "Vadose Zone (1-5, e.g., 4):  3\n",
      "Hydraulic Conductivity (e.g., 0.05):  0.07250199393968913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 7 features, but RandomForestClassifier is expecting 8 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m hydraulic_conductivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHydraulic Conductivity (e.g., 0.05): \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m predict_vulnerability(depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity)\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mpredict_vulnerability\u001b[0;34m(depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity)\u001b[0m\n\u001b[1;32m     20\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity]])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Predictions from each model\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m rf_prediction \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(input_data)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m svm_prediction \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(input_data)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m log_reg_prediction \u001b[38;5;241m=\u001b[39m log_reg_model\u001b[38;5;241m.\u001b[39mpredict(input_data)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    800\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 7 features, but RandomForestClassifier is expecting 8 features as input."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Save models after training (assuming the models are trained)\n",
    "# Note: Run this block after training models in your notebook or script.\n",
    "\n",
    "# Uncomment these lines when saving trained models\n",
    "joblib.dump(rf_model, 'random_forest_model.joblib')\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "joblib.dump(log_reg_model, 'logistic_regression_model.joblib')\n",
    "\n",
    "# Step 2: Load saved models\n",
    "rf_model = joblib.load('random_forest_model.joblib')\n",
    "svm_model = joblib.load('svm_model.joblib')\n",
    "log_reg_model = joblib.load('logistic_regression_model.joblib')\n",
    "\n",
    "# Step 3: Function to take user input and predict vulnerability\n",
    "def predict_vulnerability(depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity):\n",
    "    # Create an input array\n",
    "    input_data = np.array([[depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity]])\n",
    "\n",
    "    # Predictions from each model\n",
    "    rf_prediction = rf_model.predict(input_data)[0]\n",
    "    svm_prediction = svm_model.predict(input_data)[0]\n",
    "    log_reg_prediction = log_reg_model.predict(input_data)[0]\n",
    "\n",
    "    # Display predictions\n",
    "    print(\"Predictions for Groundwater Vulnerability (Low, Medium, High):\")\n",
    "    print(f\"Random Forest Prediction: {rf_prediction}\")\n",
    "    print(f\"SVM Prediction: {svm_prediction}\")\n",
    "    print(f\"Logistic Regression Prediction: {log_reg_prediction}\")\n",
    "\n",
    "# Step 4: Get user input and make predictions\n",
    "def main():\n",
    "    print(\"Enter the DRASTIC parameters to predict vulnerability:\")\n",
    "    depth_to_water = float(input(\"Depth to Water (e.g., 25): \"))\n",
    "    net_recharge = float(input(\"Net Recharge (e.g., 150): \"))\n",
    "    aquifer_media = int(input(\"Aquifer Media (1-5, e.g., 3): \"))\n",
    "    soil_media = int(input(\"Soil Media (1-4, e.g., 2): \"))\n",
    "    topography = float(input(\"Topography (e.g., 5): \"))\n",
    "    vadose_zone = int(input(\"Vadose Zone (1-5, e.g., 4): \"))\n",
    "    hydraulic_conductivity = float(input(\"Hydraulic Conductivity (e.g., 0.05): \"))\n",
    "\n",
    "    # Make predictions\n",
    "    predict_vulnerability(depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f7060-adb5-4ea3-aa09-dd3df05d7eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca6275f8-b20b-44cd-9d52-1cf98573d8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Assuming 'data' is your DataFrame with DRASTIC parameters and contamination category\n",
    "# Define features (X) and target (y), excluding 'Contamination_Category' from X\n",
    "X = synthetic_data[['Depth_to_Water', 'Net_Recharge', 'Aquifer_Media', 'Soil_Media', 'Topography', 'Vadose_Zone', 'Hydraulic_Conductivity']]\n",
    "y = synthetic_data['Contamination_Category']  # Target variable\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC(random_state=42)\n",
    "log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit each model\n",
    "rf_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the retrained models for later use\n",
    "joblib.dump(rf_model, 'random_forest_model.joblib')\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "joblib.dump(log_reg_model, 'logistic_regression_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7dfe9c3-71ca-4a89-a94e-472461fe74f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the DRASTIC parameters to predict vulnerability:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Depth to Water (e.g., 25):  6.878527377717779\n",
      "Net Recharge (e.g., 150):  168.02644995842303\n",
      "Aquifer Media (1-5, e.g., 3):  4\n",
      "Soil Media (1-4, e.g., 2):  3\n",
      "Topography (e.g., 5):  2.396136594242184\n",
      "Vadose Zone (1-5, e.g., 4):  3\n",
      "Hydraulic Conductivity (e.g., 0.05):  0.07250199393968913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Groundwater Vulnerability (Low, Medium, High):\n",
      "Random Forest Prediction: medium\n",
      "SVM Prediction: medium\n",
      "Logistic Regression Prediction: medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the retrained models\n",
    "rf_model = joblib.load('random_forest_model.joblib')\n",
    "svm_model = joblib.load('svm_model.joblib')\n",
    "log_reg_model = joblib.load('logistic_regression_model.joblib')\n",
    "\n",
    "# Function to predict vulnerability based on user input (7 DRASTIC parameters)\n",
    "def predict_vulnerability(depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity):\n",
    "    # Create an input array with the 7 DRASTIC parameters\n",
    "    input_data = np.array([[depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity]])\n",
    "\n",
    "    # Make predictions from each model\n",
    "    rf_prediction = rf_model.predict(input_data)[0]\n",
    "    svm_prediction = svm_model.predict(input_data)[0]\n",
    "    log_reg_prediction = log_reg_model.predict(input_data)[0]\n",
    "\n",
    "    # Display predictions\n",
    "    print(\"Predictions for Groundwater Vulnerability (Low, Medium, High):\")\n",
    "    print(f\"Random Forest Prediction: {rf_prediction}\")\n",
    "    print(f\"SVM Prediction: {svm_prediction}\")\n",
    "    print(f\"Logistic Regression Prediction: {log_reg_prediction}\")\n",
    "\n",
    "# Main function to get user input and make predictions\n",
    "def main():\n",
    "    print(\"Enter the DRASTIC parameters to predict vulnerability:\")\n",
    "    depth_to_water = float(input(\"Depth to Water (e.g., 25): \"))\n",
    "    net_recharge = float(input(\"Net Recharge (e.g., 150): \"))\n",
    "    aquifer_media = int(input(\"Aquifer Media (1-5, e.g., 3): \"))\n",
    "    soil_media = int(input(\"Soil Media (1-4, e.g., 2): \"))\n",
    "    topography = float(input(\"Topography (e.g., 5): \"))\n",
    "    vadose_zone = int(input(\"Vadose Zone (1-5, e.g., 4): \"))\n",
    "    hydraulic_conductivity = float(input(\"Hydraulic Conductivity (e.g., 0.05): \"))\n",
    "\n",
    "    # Make predictions\n",
    "    predict_vulnerability(depth_to_water, net_recharge, aquifer_media, soil_media, topography, vadose_zone, hydraulic_conductivity)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f501c-8df6-4c34-8242-3342c7b01834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
